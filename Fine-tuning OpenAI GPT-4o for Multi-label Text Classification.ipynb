{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f0e2b2c",
   "metadata": {},
   "source": [
    "## Detailed Article Explaination\n",
    "\n",
    "The detailed code explanation for this article is available at the following link:\n",
    "\n",
    "https://www.daniweb.com/programming/computer-science/tutorials/542648/fine-tuning-openai-gpt-4o-for-multi-label-text-classification\n",
    "\n",
    "For my other articles for Daniweb.com, please see this link:\n",
    "\n",
    "https://www.daniweb.com/members/1235222/usmanmalik57"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e48554",
   "metadata": {},
   "source": [
    "## Importing and Installing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01c58243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\usman\\anaconda3\\lib\\site-packages (1.52.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\usman\\anaconda3\\lib\\site-packages (from openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\usman\\anaconda3\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\usman\\anaconda3\\lib\\site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\usman\\anaconda3\\lib\\site-packages (from openai) (0.5.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\usman\\anaconda3\\lib\\site-packages (from openai) (2.9.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\usman\\anaconda3\\lib\\site-packages (from openai) (1.2.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\usman\\anaconda3\\lib\\site-packages (from openai) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\usman\\anaconda3\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\usman\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: certifi in c:\\users\\usman\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\usman\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\usman\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\usman\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\usman\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\usman\\anaconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d272f5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import combinations\n",
    "from collections import Counter\n",
    "from sklearn.metrics import hamming_loss, accuracy_score\n",
    "import json\n",
    "import os\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3196628b",
   "metadata": {},
   "source": [
    "## Importing and Preprocessing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83ec67d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (20972, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>ABSTRACT</th>\n",
       "      <th>Computer Science</th>\n",
       "      <th>Physics</th>\n",
       "      <th>Mathematics</th>\n",
       "      <th>Statistics</th>\n",
       "      <th>Quantitative Biology</th>\n",
       "      <th>Quantitative Finance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Reconstructing Subject-Specific Effect Maps</td>\n",
       "      <td>Predictive models allow subject-specific inf...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Rotation Invariance Neural Network</td>\n",
       "      <td>Rotation invariance and translation invarian...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Spherical polyharmonics and Poisson kernels fo...</td>\n",
       "      <td>We introduce and develop the notion of spher...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>A finite element approximation for the stochas...</td>\n",
       "      <td>The stochastic Landau--Lifshitz--Gilbert (LL...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Comparative study of Discrete Wavelet Transfor...</td>\n",
       "      <td>Fourier-transform infra-red (FTIR) spectra o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                              TITLE  \\\n",
       "0   1        Reconstructing Subject-Specific Effect Maps   \n",
       "1   2                 Rotation Invariance Neural Network   \n",
       "2   3  Spherical polyharmonics and Poisson kernels fo...   \n",
       "3   4  A finite element approximation for the stochas...   \n",
       "4   5  Comparative study of Discrete Wavelet Transfor...   \n",
       "\n",
       "                                            ABSTRACT  Computer Science  \\\n",
       "0    Predictive models allow subject-specific inf...                 1   \n",
       "1    Rotation invariance and translation invarian...                 1   \n",
       "2    We introduce and develop the notion of spher...                 0   \n",
       "3    The stochastic Landau--Lifshitz--Gilbert (LL...                 0   \n",
       "4    Fourier-transform infra-red (FTIR) spectra o...                 1   \n",
       "\n",
       "   Physics  Mathematics  Statistics  Quantitative Biology  \\\n",
       "0        0            0           0                     0   \n",
       "1        0            0           0                     0   \n",
       "2        0            1           0                     0   \n",
       "3        0            1           0                     0   \n",
       "4        0            0           1                     0   \n",
       "\n",
       "   Quantitative Finance  \n",
       "0                     0  \n",
       "1                     0  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## dataset download link\n",
    "## https://www.kaggle.com/datasets/shivanandmn/multilabel-classification-dataset?select=train.csv\n",
    "\n",
    "dataset = pd.read_csv(r\"D:\\Datasets\\Multilabel Research Paper Classification\\train.csv\")\n",
    "print(f\"Dataset Shape: {dataset.shape}\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a9ba82a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Dataset Shape: (5044, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>ABSTRACT</th>\n",
       "      <th>Computer Science</th>\n",
       "      <th>Physics</th>\n",
       "      <th>Mathematics</th>\n",
       "      <th>Statistics</th>\n",
       "      <th>Quantitative Biology</th>\n",
       "      <th>Quantitative Finance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Comparative study of Discrete Wavelet Transfor...</td>\n",
       "      <td>Fourier-transform infra-red (FTIR) spectra o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Many-Body Localization: Stability and Instability</td>\n",
       "      <td>Rare regions with weak disorder (Griffiths r...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Minimax Estimation of the $L_1$ Distance</td>\n",
       "      <td>We consider the problem of estimating the $L...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Density large deviations for multidimensional ...</td>\n",
       "      <td>We investigate the density large deviation f...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>mixup: Beyond Empirical Risk Minimization</td>\n",
       "      <td>Large deep neural networks are powerful, but...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID                                              TITLE  \\\n",
       "4    5  Comparative study of Discrete Wavelet Transfor...   \n",
       "21  22  Many-Body Localization: Stability and Instability   \n",
       "28  29           Minimax Estimation of the $L_1$ Distance   \n",
       "29  30  Density large deviations for multidimensional ...   \n",
       "30  31          mixup: Beyond Empirical Risk Minimization   \n",
       "\n",
       "                                             ABSTRACT  Computer Science  \\\n",
       "4     Fourier-transform infra-red (FTIR) spectra o...                 1   \n",
       "21    Rare regions with weak disorder (Griffiths r...                 0   \n",
       "28    We consider the problem of estimating the $L...                 0   \n",
       "29    We investigate the density large deviation f...                 0   \n",
       "30    Large deep neural networks are powerful, but...                 1   \n",
       "\n",
       "    Physics  Mathematics  Statistics  Quantitative Biology  \\\n",
       "4         0            0           1                     0   \n",
       "21        1            1           0                     0   \n",
       "28        0            1           1                     0   \n",
       "29        1            1           0                     0   \n",
       "30        0            0           1                     0   \n",
       "\n",
       "    Quantitative Finance  \n",
       "4                      0  \n",
       "21                     0  \n",
       "28                     0  \n",
       "29                     0  \n",
       "30                     0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjects = [\"Computer Science\", \"Physics\", \"Mathematics\", \"Statistics\", \"Quantitative Biology\", \"Quantitative Finance\"]\n",
    "filtered_dataset = dataset[(dataset[subjects] == 1).sum(axis=1) >= 2]\n",
    "print(f\"Filtered Dataset Shape: {filtered_dataset.shape}\")\n",
    "filtered_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b17721c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Shape: (100, 9)\n",
      "Testing Dataset Shape: (100, 9)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = filtered_dataset.iloc[:100]  # First 100 records for training\n",
    "test_dataset = filtered_dataset.sample(n=100, random_state=42)  # randomly selecting 100 records for testing\n",
    "\n",
    "# Display the shapes of the resulting datasets\n",
    "print(f\"Training Dataset Shape: {train_dataset.shape}\")\n",
    "print(f\"Testing Dataset Shape: {test_dataset.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df82a842",
   "metadata": {},
   "source": [
    "## Creating a Training File for OpenAI Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de314e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize list to hold JSON-like strings\n",
    "json_lines = []\n",
    "\n",
    "# Template for system role content\n",
    "system_content = (\n",
    "    \"You are an expert in various scientific domains.\\n\"\n",
    "    \"Given the following research paper title and abstract, classify the research paper into at least two or more of the following categories:\\n\"\n",
    "    \"- Computer Science\\n\"\n",
    "    \"- Physics\\n\"\n",
    "    \"- Mathematics\\n\"\n",
    "    \"- Statistics\\n\"\n",
    "    \"- Quantitative Biology\\n\"\n",
    "    \"- Quantitative Finance\\n\\n\"\n",
    "    \"Return only a comma-separated list of the categories (e.g., [Computer Science,Physics] or [Computer Science,Physics,Mathematics]).\\n\"\n",
    "    \"Use the exact case sensitivity and spelling of the categories provided above.\"\n",
    ")\n",
    "\n",
    "# Loop through each row in the DataFrame\n",
    "for _, row in train_dataset.iterrows():\n",
    "    # Identify the categories with a value of 1 and reverse the list\n",
    "    categories = [\n",
    "        subject for subject in [\"Computer Science\", \"Physics\", \"Mathematics\", \"Statistics\", \"Quantitative Biology\", \"Quantitative Finance\"]\n",
    "        if row[subject] == 1\n",
    "    ][::-1]  # Reverse the order of categories\n",
    "    \n",
    "    # Create JSON structure for each row\n",
    "    json_record = {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system_content},\n",
    "            {\"role\": \"user\", \"content\": f\"Title: {row['TITLE']}\\nAbstract: {row['ABSTRACT']}\"},\n",
    "            {\"role\": \"assistant\", \"content\": f\"[{','.join(categories)}]\"}\n",
    "        ]\n",
    "    }\n",
    "    # Convert to JSON string and add to list\n",
    "    json_lines.append(json.dumps(json_record))\n",
    "\n",
    "# Join all JSON strings with newline separators for the final output\n",
    "final_output = \"\\n\".join(json_lines)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9cfe4848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully saved to 'train.json'\n"
     ]
    }
   ],
   "source": [
    "# Save the JSON records to 'train.json'\n",
    "\n",
    "training_file_path = r\"D:\\Datasets\\Multilabel Research Paper Classification\\train.json\"\n",
    "\n",
    "with open(training_file_path, 'w') as file:\n",
    "    file.write(final_output)\n",
    "\n",
    "print(\"Data successfully saved to 'train.json'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af2a692",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key = os.environ.get('OPENAI_API_KEY'),\n",
    ")\n",
    "\n",
    "\n",
    "training_file = client.files.create(\n",
    "  file=open(training_file_path, \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "print(training_file.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0659500f",
   "metadata": {},
   "source": [
    "## Fine Tuning GPT-4o Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63b1dca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuning_job_gpt4o = client.fine_tuning.jobs.create(\n",
    "  training_file=training_file.id,\n",
    "  model=\"gpt-4o-2024-08-06\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48dbbe47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List up to 10 events from a fine-tuning job\n",
    "print(client.fine_tuning.jobs.list_events(fine_tuning_job_id = fine_tuning_job_gpt4o.id,\n",
    "                                    limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501aeedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model_id = client.fine_tuning.jobs.retrieve(fine_tuning_job_gpt4o.id).fine_tuned_model\n",
    "print(ft_model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041ffa08",
   "metadata": {},
   "source": [
    "## Predicting Research Paper Category with Fine-tuned GPT-4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0b44e286",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_research_category(client, model, dataset):\n",
    "\n",
    "    outputs = []\n",
    "    i = 0\n",
    "\n",
    "    for _, row in dataset.iterrows():\n",
    "        title = row['TITLE']\n",
    "        abstract = row['ABSTRACT']\n",
    "\n",
    "        content = \"\"\"You are an expert in various scientific domains.\n",
    "                     Given the following research paper title and abstract, classify the research paper into at least two or more of the following categories:\n",
    "                    - Computer Science\n",
    "                    - Physics\n",
    "                    - Mathematics\n",
    "                    - Statistics\n",
    "                    - Quantitative Biology\n",
    "                    - Quantitative Finance\n",
    "\n",
    "                    Return only a comma-separated list of the categories (e.g., [Computer Science,Physics] or [Computer Science,Physics,Mathematics]).\n",
    "                    Use the exact case sensitivity and spelling of the categories provided above.\n",
    "\n",
    "                    text: Title: {}\\nAbstract: {}\"\"\".format(title, abstract)\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "        research_category = client.chat.completions.create(\n",
    "                                model= model,\n",
    "                                temperature = 0,\n",
    "                                max_tokens = 100,\n",
    "                                messages=[\n",
    "                                      {\"role\": \"user\", \"content\": content}\n",
    "                                  ]\n",
    "                              ).choices[0].message.content\n",
    "\n",
    "\n",
    "        outputs.append(research_category)\n",
    "        print(i + 1, research_category)\n",
    "        i += 1\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7b2e094c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def parse_outputs_to_dataframe(outputs):\n",
    "\n",
    "    subjects = [\"Computer Science\", \"Physics\", \"Mathematics\", \"Statistics\", \"Quantitative Biology\", \"Quantitative Finance\"]\n",
    "    # Remove square brackets and split the subjects for each entry in outputs\n",
    "    parsed_data = [item.strip('[]').split(',') for item in outputs]\n",
    "\n",
    "    # Create an empty DataFrame with columns for each subject, initializing with 0s\n",
    "    df = pd.DataFrame(0, index=range(len(parsed_data)), columns=subjects)\n",
    "\n",
    "    # Populate the DataFrame with 1s based on the presence of each subject in each row\n",
    "    for i, subjects_list in enumerate(parsed_data):\n",
    "        for subject in subjects_list:\n",
    "            if subject in subjects:\n",
    "                df.loc[i, subject] = 1\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "25b820b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [Mathematics,Physics]\n",
      "2 [Statistics,Mathematics]\n",
      "3 [Statistics,Computer Science]\n",
      "4 [Statistics,Mathematics]\n",
      "5 [Statistics,Computer Science]\n",
      "6 [Statistics,Mathematics]\n",
      "7 [Mathematics,Computer Science]\n",
      "8 [Statistics,Computer Science]\n",
      "9 [Statistics,Computer Science]\n",
      "10 [Mathematics,Computer Science]\n",
      "11 [Statistics,Computer Science]\n",
      "12 [Statistics,Computer Science]\n",
      "13 [Statistics,Physics,Computer Science]\n",
      "14 [Statistics,Computer Science]\n",
      "15 [Statistics,Computer Science]\n",
      "16 [Statistics,Mathematics]\n",
      "17 [Statistics,Mathematics]\n",
      "18 [Statistics,Computer Science]\n",
      "19 [Statistics,Computer Science]\n",
      "20 [Mathematics,Computer Science]\n",
      "21 [Statistics,Mathematics]\n",
      "22 [Mathematics,Computer Science]\n",
      "23 [Statistics,Mathematics]\n",
      "24 [Statistics,Computer Science]\n",
      "25 [Mathematics,Computer Science]\n",
      "26 [Statistics,Computer Science]\n",
      "27 [Statistics,Computer Science]\n",
      "28 [Quantitative Biology,Computer Science]\n",
      "29 [Mathematics,Physics]\n",
      "30 [Statistics,Computer Science]\n",
      "31 [Statistics,Computer Science]\n",
      "32 [Statistics,Computer Science]\n",
      "33 [Statistics,Computer Science]\n",
      "34 [Statistics,Mathematics,Computer Science]\n",
      "35 [Statistics,Computer Science]\n",
      "36 [Statistics,Computer Science]\n",
      "37 [Statistics,Physics]\n",
      "38 [Statistics,Computer Science]\n",
      "39 [Statistics,Computer Science]\n",
      "40 [Statistics,Computer Science]\n",
      "41 [Statistics,Mathematics]\n",
      "42 [Statistics,Computer Science]\n",
      "43 [Statistics,Mathematics]\n",
      "44 [Statistics,Computer Science]\n",
      "45 [Statistics,Physics]\n",
      "46 [Statistics,Computer Science]\n",
      "47 [Statistics,Computer Science]\n",
      "48 [Mathematics,Computer Science]\n",
      "49 [Statistics,Computer Science]\n",
      "50 [Mathematics,Computer Science]\n",
      "51 [Statistics,Mathematics]\n",
      "52 [Statistics,Mathematics]\n",
      "53 [Statistics,Computer Science]\n",
      "54 [Statistics,Computer Science]\n",
      "55 [Statistics,Computer Science]\n",
      "56 [Mathematics,Computer Science]\n",
      "57 [Statistics,Computer Science]\n",
      "58 [Mathematics,Computer Science]\n",
      "59 [Mathematics,Computer Science]\n",
      "60 [Mathematics,Physics]\n",
      "61 [Statistics,Computer Science]\n",
      "62 [Mathematics,Physics]\n",
      "63 [Statistics,Computer Science]\n",
      "64 [Mathematics,Physics]\n",
      "65 [Statistics,Computer Science]\n",
      "66 [Statistics,Mathematics]\n",
      "67 [Mathematics,Computer Science]\n",
      "68 [Statistics,Computer Science]\n",
      "69 [Statistics,Computer Science]\n",
      "70 [Statistics,Mathematics]\n",
      "71 [Statistics,Computer Science]\n",
      "72 [Statistics,Computer Science]\n",
      "73 [Statistics,Computer Science]\n",
      "74 [Statistics,Computer Science]\n",
      "75 [Statistics,Computer Science]\n",
      "76 [Statistics,Computer Science]\n",
      "77 [Mathematics,Physics,Computer Science]\n",
      "78 [Statistics,Mathematics]\n",
      "79 [Mathematics,Computer Science]\n",
      "80 [Statistics,Computer Science]\n",
      "81 [Statistics,Computer Science]\n",
      "82 [Mathematics,Computer Science]\n",
      "83 [Statistics,Mathematics]\n",
      "84 [Statistics,Computer Science]\n",
      "85 [Statistics,Computer Science]\n",
      "86 [Statistics,Computer Science]\n",
      "87 [Statistics,Computer Science]\n",
      "88 [Mathematics,Computer Science]\n",
      "89 [Statistics,Physics]\n",
      "90 [Mathematics,Computer Science]\n",
      "91 [Statistics,Computer Science]\n",
      "92 [Statistics,Computer Science]\n",
      "93 [Statistics,Mathematics]\n",
      "94 [Statistics,Computer Science]\n",
      "95 [Statistics,Mathematics]\n",
      "96 [Physics,Computer Science]\n",
      "97 [Statistics,Computer Science]\n",
      "98 [Statistics,Computer Science]\n",
      "99 [Statistics,Computer Science]\n",
      "100 [Statistics,Physics]\n"
     ]
    }
   ],
   "source": [
    "model = ft_model_id\n",
    "outputs = find_research_category(client, \n",
    "                                 model, \n",
    "                                 test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d624fdf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming Loss: 0.09333333333333334\n",
      "Subset Accuracy: 0.69\n"
     ]
    }
   ],
   "source": [
    "predictions = parse_outputs_to_dataframe(outputs)\n",
    "targets = test_dataset[subjects]\n",
    "\n",
    "# Calculate Hamming Loss\n",
    "hamming = hamming_loss(targets, predictions)\n",
    "print(f\"Hamming Loss: {hamming}\")\n",
    "\n",
    "# Calculate Subset Accuracy (Exact Match Ratio)\n",
    "subset_accuracy = accuracy_score(targets, predictions)\n",
    "print(f\"Subset Accuracy: {subset_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1341d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
